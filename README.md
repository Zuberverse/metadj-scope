# MetaDJ Scope

**Last Modified**: 2025-12-26 15:21 EST

Hackathon exploration project for the Daydream Scope Track (Interactive AI Video Program). Building a Scope-generated MetaDJ avatar from webcam input for a real-time streaming demo.

## Status
- **Phase**: Hackathon active - using native Scope UI
- **Stack**: Next.js 16 + TypeScript + Tailwind 4 (ready for future custom UI)
- **Direction**: MetaDJ avatar generated by Scope from live webcam input
- **RunPod**: Deployed (`metadj-scope` on RTX 5090)
- **Reference Image**: MetaDJ v7.0 avatar for VACE identity consistency

## UI Approach

**For hackathon**: Use native Scope platform UI directly at the RunPod instance. The Scope UI already provides webcam input, VACE controls, prompt editing, and output display—no need to build custom UI for the demo.

**For future**: Next.js 16 project is scaffold-only; custom UI/UX is deferred until after the hackathon.

**Access Scope UI**: https://gbc63llq1zdxki-8000.proxy.runpod.net

## Hackathon Context
- **Program**: Daydream 2025 Interactive AI Video Program (Scope Track)
- **Timeline**: Dec 22 - Jan 8 (two-week sprint)
- **Prizes**: $2,500 / $1,750 / $750 for top 3
- **Details**: See `docs/scope.md`

## MetaDJ Alignment
This project connects to the broader MetaDJ ecosystem:
- **MetaDJ Studio**: Virtual stage performance engine—Scope could power real-time visuals
- **MetaDJ Dream**: AI-driven creative tool—same StreamDiffusion foundation
- **MetaDJ Avatar**: VACE enables character-consistent generation for the MetaDJ persona

**Technical Advantage**: Z has production experience with StreamDiffusion via MetaDJ Nexus Dream feature. Proven ControlNet configurations, timing patterns, and prompt engineering transfer directly to Scope.

## Active Instance

| Property | Value |
|----------|-------|
| **Pod Name** | metadj-scope |
| **Pod ID** | `gbc63llq1zdxki` |
| **GPU** | RTX 5090 (32GB VRAM) |
| **Scope UI** | https://gbc63llq1zdxki-8000.proxy.runpod.net |
| **Console** | [RunPod Dashboard](https://console.runpod.io/pods?id=gbc63llq1zdxki) |
| **Cost** | $0.89/hr (On-Demand) |

> **Note**: Stop the pod when not in use to conserve credits. Restart from the RunPod console when needed.

## Pipeline Selection (Quick Reference)

**For MetaDJ avatar demo, use `longlive` + VACE** (identity consistency > photorealism).

| Pipeline | Best For | VACE | VRAM |
|----------|----------|------|------|
| **`longlive`** ⭐ | Identity-consistent avatars | ✅ Yes | ~20GB |
| `krea-realtime-video` | Photorealistic portraits | ❌ No | 32GB |
| `streamdiffusionv2` | General-purpose | TBD | ~20GB |
| `passthrough` | Debug webcam | N/A | Minimal |

**Key Trade-off**: `longlive` produces stylized output but locks MetaDJ identity via VACE. `krea-realtime-video` is photorealistic but has no identity consistency.

See `docs/scope-technical.md` for complete pipeline documentation.

## Quick Start

### Prerequisites
- Node.js 20.19+
- npm

### Using Scope (Hackathon Workflow)

1. Start the RunPod pod from the [console](https://console.runpod.io/pods?id=gbc63llq1zdxki)
2. Wait for startup (~2-3 minutes)
3. Open the [Scope UI](https://gbc63llq1zdxki-8000.proxy.runpod.net)
4. Enable VACE and upload MetaDJ reference image
5. Configure prompt and start generation
6. Stop pod when done to save credits

### Local Development (Future Custom UI)

```bash
# Install dependencies
npm install

# Start development server (port 2000)
npm run dev

# Build for production
npm run build

# Type check
npm run type-check
```

Local dev server: http://localhost:2000
Note: UI scaffolding only; stream controls are not wired to the Scope API yet.

## Commands
| Command | Description |
| --- | --- |
| `npm run dev` | Start development server (port 2000) |
| `npm run dev:turbo` | Start with Turbopack |
| `npm run build` | Build for production |
| `npm run start` | Start production server |
| `npm run lint` | Run ESLint |
| `npm run type-check` | TypeScript type check |
| `npm run test` | Run tests |

## Architecture
- MVP architecture defined in `docs/architecture.md`
- **Current**: Native Scope UI for hackathon
- **Future**: Custom UI components in `src/components/`
- **API Client**: `src/lib/scope/` - typed Scope API client (for future integration)

## Environment Variables
See `.env.example` for the full list and comments.

| Variable | Required | Description |
| --- | --- | --- |
| `HF_TOKEN` | RunPod only | HuggingFace token for TURN server when deploying Scope on RunPod |
| `NEXT_PUBLIC_SCOPE_API_URL` | Local UI only | Scope API server base URL for the scaffolded UI |
| `LIVEPEER_API_KEY` | Optional | Future Livepeer integration |

## Documentation

### Core Docs
- `docs/scope.md` - Hackathon brief and requirements
- `docs/scope-technical.md` - Scope technical capabilities
- `docs/strategy.md` - Goals, constraints, decision points
- `docs/architecture.md` - System design
- `docs/features/avatar-mvp-spec.md` - MVP requirements
- `docs/research.md` - Scope API research
- `docs/nexus-daydream-reference.md` - StreamDiffusion patterns from MetaDJ Nexus

### Reference
- `docs/api/` - API integration notes
- `docs/features/` - Feature specifications
- `tools.md` - Tools and integrations
- `CHANGELOG.md` - Project milestones

## Key Decisions
1. **UI Approach**: Native Scope UI for hackathon; custom UI deferred (Dec 26)
2. **Deployment**: RunPod with RTX 5090
3. **Stack**: Next.js 16 + Tailwind 4 (matches MetaDJ Nexus)
4. **Pipeline**: `longlive` + VACE for identity consistency (Dec 26)
5. **Future**: Masking/segmentation and background environments

## Resources

### External
- [Scope GitHub](https://github.com/daydreamlive/scope/)
- [Scope Docs](https://docs.daydream.live/scope/introduction)
- [VACE API Docs](https://github.com/daydreamlive/scope/blob/main/docs/api/vace.md)
- [RunPod Quickstart](https://docs.daydream.live/scope/getting-started/quickstart#cloud-deployment-runpod)
- [RunPod Scope Template](https://runpod.io/console/deploy?template=daydream-scope)

## License
Proprietary (internal) unless updated.
