# MetaDJ Avatar MVP Spec (Scope)

**Last Modified**: 2025-12-26 12:37 EST
**Status**: Draft

## Overview
Build a real-time MetaDJ avatar generated by Scope from live webcam input. Scope is the rendering engine; VACE locks identity; ControlNet guides pose. The demo must run reliably for the Jan 9 checkpoint.

## Goals
- Prove a Scope-generated avatar can embody MetaDJ identity in real time.
- Deliver a stable, demo-ready flow: webcam in, avatar out.
- Keep controls minimal and latency low.

## Non-Goals (MVP)
- TouchDesigner integration
- Advanced compositing or multi-layer pipelines
- Full-body tracking or multi-person tracking
- Perfect alpha/mask output (future)

## User Flow (MVP)
1. Open demo.
2. Select MetaDJ avatar preset.
3. Start stream.
4. Webcam drives the live avatar output.

## Functional Requirements

### P0 (Must Have)
- Start and stop a Scope stream.
- Provide VACE reference images to lock MetaDJ identity.
- Ingest webcam input (API or desktop app).
- Render live avatar output with consistent identity.
- Show basic status (warming, live, error).

### P1 (Should Have)
- Prompt presets for MetaDJ styles (e.g., default, high-contrast, neon).
- Simple intensity control (guidance, delta, or ControlNet scale).
- Record a short demo capture.

## Technical Requirements

### Scope Pipeline (Baseline)
- Model: TBD (candidate models in `docs/scope-technical.md`)
- Resolution: TBD (start at 512x512 if supported)
- Steps: TBD (target ~25 if supported)
- Guidance: TBD (target ~1.0 if supported)
- Delta: TBD (target ~0.7 if supported)
- ControlNet: OpenPose if supported; optional depth/edges if latency allows.

### VACE
- Reference set: curated MetaDJ avatar images (3-8 images).
- Validate input format (URL/base64/file) against Scope API.

### Dynamic Parameters
- Update only live-safe parameters to avoid pipeline reloads (confirm via Scope API docs).
- Start with prompt, guidance, delta, ControlNet scale if supported.

## UI Requirements
- Minimal control panel:
  - Start/stop
  - Preset selector
  - Status indicator
- Output viewer for the live stream.

## Performance Targets
- Warm-up time: under 30s.
- Stable output without frequent resets.
- Latency low enough for a conversational demo.

## Demo Requirements
- 1-minute narrative: "Webcam in, Scope out, MetaDJ embodied."
- Single click to start once configured.
- Fallback plan if RunPod or local GPU fails.

## Future Enhancements
- Masking/segmentation for clean overlay (SAM3 or similar).
- Background environment layer generated by Scope.
- TouchDesigner or Spout pipeline for live performance control.

## Open Questions
- Best webcam ingest path (API vs desktop app)?
- VACE input format and latency impact?
- Does Scope expose segmentation or alpha output?
